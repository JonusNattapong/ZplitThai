{
  "unk_token": {
    "content": "<unk>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "pad_token": {
    "content": "<pad>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "bos_token": {
    "content": "<s>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "eos_token": {
    "content": "</s>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "mask_token": {
    "content": "<mask>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "cls_token": {
    "content": "<cls>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "sep_token": {
    "content": "<sep>",
    "single_word": false,
    "lstrip": false,
    "rstrip": false,
    "normalized": true,
    "__type": "AddedToken"
  },
  "model_max_length": 2048,
  "tokenizer_class": "PreTrainedTokenizerFast",
  "auto_map": {
    "AutoTokenizer": [
      "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast",
      null
    ]
  },
  "model_type": "unigram",
  "vocab_size": 10000,
  "language": [
    "th",
    "thai"
  ],
  "license": "apache-2.0",
  "library_name": "tokenizers",
  "tags": [
    "thai",
    "tokenizer",
    "nlp",
    "subword"
  ],
  "thai_engine": "newmm",
  "creation_date": "2025-07-02 21:02:41",
  "vocab_stats": {
    "total_tokens": 2040,
    "special_tokens": 1,
    "thai_tokens": 2032,
    "numeric_tokens": 2
  }
}